# 第25〜28ラウンド：裁判制度の耐用年数、プライバシー法の未来、TACIEの倫理学

## 裁判制度の耐用年数

### 裁判の本質的機能（田中）

裁判制度の核心的機能は3つ：
1. **紛争解決**：当事者間の争いを公正に解決する
2. **法の解釈**：法律の意味を確定し、先例を形成する
3. **権力統制**：国家権力（立法・行政）を法的にチェックする

### AI時代の裁判の変容

| 機能 | AI化の可能性 | 限界 |
|------|------------|------|
| 紛争解決 | **高い**。少額訴訟、定型的紛争はODRで代替可能 | 複雑な事実認定、証拠評価は困難 |
| 法の解釈 | **中程度**。判例分析は得意だが、新しい解釈の「創造」は困難 | 社会の変化に応じた創造的解釈は人間にしかできない |
| 権力統制 | **低い**。政治的判断を伴う違憲審査はAIに委ねるべきでない | 民主主義の最後の砦としての裁判所の役割 |

### 裁判所の「解釈負債」（中村）

- 日本の最高裁は「統治行為論」で政治的問題の判断を回避する傾向
- 砂川事件（1959年）以降、安全保障問題での違憲審査を実質的に放棄
- これは裁判所自体の「解釈負債」——**司法の機能不全**
- TACIEが立法過程を改善しても、司法が機能不全のままでは片手落ち

### Online Dispute Resolution（ODR）の展開（サラ）

| プラットフォーム | 対象 | 規模 |
|----------------|------|------|
| eBay Resolution Center | EC取引紛争 | 年間6,000万件の紛争処理 |
| Modria | 消費者紛争 | 複数の州で採用 |
| Money Claim Online（英国） | 少額金銭訴訟 | 政府運営のODR |
| Rechtwijzer（オランダ） | 離婚調停 | AIガイド付き |

**eBayは年間6,000万件の紛争を処理している。これは世界中の裁判所の処理件数を合わせたより多い。**

### 裁判のバイアスとAI（山本）

- COMPAS（再犯予測AI）のバイアスが示したように、AIは既存の偏見を増幅しうる
- しかし人間の裁判官にもバイアスがある：
  - 「空腹効果」：昼食前の判決は厳しい傾向（イスラエルの研究）
  - 人種バイアス：同じ犯罪でも人種により量刑が異なる（アメリカの研究）
- **AIと人間、どちらがより公正か？**は実証的な問い
- 最善は**AI＋人間のハイブリッド**：AIが判例分析・事実整理を行い、人間が最終判断

---

## プライバシー法の未来——監視社会と法の関係

### プライバシー概念の変遷（鈴木）

| 時代 | プライバシーの概念 | 法的表現 |
|------|-----------------|---------|
| 19世紀末 | 「一人にしておいてもらう権利」（ウォーレン＆ブランダイス） | 不法行為法 |
| 20世紀中盤 | 「自己情報コントロール権」 | データ保護法 |
| 21世紀 | 「プロファイリングされない権利」「予測されない権利」 | **法的空白** |

### AI時代のプライバシー侵害の新形態

#### 1. 推論プライバシー（Inferential Privacy）
- AIが公開データから非公開情報を推論する
- 例：購買履歴から政治的傾向、健康状態、性的指向を推定
- 「本人が開示していない情報をAIが推論で生成する」場合の法的保護は？

#### 2. 集団プライバシー
- 個人のデータは保護されていても、集団データの分析から個人の属性が推定できる
- 「自分のデータを提供していなくても、類似集団のデータからプロファイリングされる」

#### 3. 時間的プライバシー
- AIが過去の行動データから未来の行動を予測する
- 「まだ行っていないことについて判断される」リスク
- 「マイノリティ・リポート」問題のプライバシー版

### 各国のアプローチ比較（中村）

| 法域 | アプローチ | 特徴 |
|------|----------|------|
| EU（GDPR） | 権利ベース | プロファイリングへの異議権（22条） |
| アメリカ | セクター別規制 | 統一連邦法なし、州法の断片化 |
| 中国 | 国家管理型 | 個人情報保護法あるが国家の監視は別 |
| 日本 | 個人情報保護法 | GDPR十分性認定を受けたが、AIプロファイリングへの対応は弱い |

### TACIEによるプライバシー法の常時更新の必要性（サラ）

- テクノロジーの進化速度 >> プライバシー法の改正速度
- 新しいプライバシー侵害の形態が数ヶ月単位で出現
- **プライバシー法はTACIEが最も必要な領域の一つ**
- サンドボックス＋AIモニタリングによる「動的プライバシー規制」の提案

---

## TACIEの倫理学

### 技術を使って法を変えることの倫理的正当性（鈴木による整理）

#### 正当化論拠

1. **帰結主義的正当化**：TACIEの結果として、より良い法律が生まれ、社会的厚生が増大するなら正当
2. **手続的正当化**：TACIEのプロセスが透明で包摂的であれば、結果にかかわらず正当
3. **人権的正当化**：TACIEが基本的人権をより良く保護するなら正当

#### 倫理的リスク

1. **テクノロジー決定論の罠**：技術で解決できるという幻想がより根本的な社会問題を隠蔽
2. **民主主義の技術化**：政治的判断が技術的判断に置き換えられ、政治の本質が失われる
3. **責任の拡散**：AI＋市民＋議会の複合的プロセスで、失敗時に誰も責任を取らない

### 「良い法律」とは何か（ロッシ）

- 効率的な法律？公正な法律？安定した法律？人々に愛される法律？
- これらは時に相互に矛盾する
- TACIEが「法の最適化」を目指すとき、何を最適化するのかが問われる
- **法の「良さ」は多次元的であり、単一の最適化関数では表現できない**

### 倫理的ガードレールの設計（田中）

TACIEの倫理的枠組みとして、以下の5原則を提案：

1. **人間中心原則**：最終決定は常に人間が行う
2. **透明性原則**：AIの判断プロセスは完全に公開される
3. **包摂性原則**：すべての市民に参加の機会が保障される
4. **可逆性原則**：AIの提案に基づく変更は、撤回可能でなければならない
5. **尊厳保護原則**：人間の尊厳を損なう変更は、いかなる合理的根拠があっても許されない

## 次のラウンドへの問い
1. 国際法の耐用年数——ウェストファリア体制の終焉はいつ来るか？
2. TACIEのグローバル版——国際機関のガバナンス改革
3. テクノロジーが生み出す新しい法的概念——「デジタル人権」の構想
